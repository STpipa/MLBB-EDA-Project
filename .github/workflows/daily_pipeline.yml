name: Daily MLBB Data Pipeline

on:
  # Define la frecuencia de ejecuciÃ³n diaria
  schedule:
    # Puedes usar un cron job para esto. 
    - cron: '0 0 * * *'
  # Permite ejecutar el workflow manualmente desde la interfaz de GitHub
  workflow_dispatch:

# ðŸš¨ BLOQUE DE PERMISOS CRÃTICO ðŸš¨
permissions:
  contents: write # Â¡Esto le da permiso al bot para hacer push!

jobs:
  run_pipeline:
    runs-on: ubuntu-latest # Usa una mÃ¡quina virtual de Linux
    
    steps:
      - name: Checkout del cÃ³digo
        uses: actions/checkout@v4

      - name: Configurar Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11' # AsegÃºrate de usar la versiÃ³n correcta 

      - name: Instalar dependencias
        
        run: pip install -r requirements.txt

        # ðŸš¨ Configurar PYTHONPATH ðŸš¨
      - name: Set PYTHONPATH
        # Esto aÃ±ade el directorio actual (la raÃ­z del proyecto) al PYTHONPATH
        # para que Python pueda encontrar 'src' al usar 'from src.module import...'
        run: echo "PYTHONPATH=$(pwd)" >> $GITHUB_ENV

      - name: ðŸš€ Ejecutar el Pipeline Diario
        # Asumiendo que pipeline_daily.py estÃ¡ en la raÃ­z o en src/
        run: python src/pipeline_daily.py

      - name: ðŸ’¾ Commit y Push de los datos actualizados
        # Necesario para que el Streamlit Cloud Dashboard acceda a los archivos actualizados
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: 'ðŸ¤– ETL: Datos y reportes actualizados (Job Diario)'
          # Los archivos que generas y deben ser subidos
          file_pattern: 'data/*.csv reports/*.txt reports/*.png'